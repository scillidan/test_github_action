name: Create Releases (*-eng)

on:
  schedule:
    # 00:00 on the 1st of every month (UTC)
    - cron: '0 0 1 * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  discover-dictionaries:
    runs-on: ubuntu-latest
    outputs:
      dictionaries: ${{ steps.set-output.outputs.dictionaries }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl

      - name: Discover all *-eng dictionaries
        id: discover
        run: |
          # Fetch the main dictionary listing page
          html=$(curl -s -L -A "GitHub-Actions-CI" "https://download.freedict.org/dictionaries/")

          # Extract all language pair links
          lang_links=$(echo "$html" | grep -oP 'href="([a-z]{3}-[a-z]{3}/)"' | grep -oP '[a-z]{3}-[a-z]{3}' || true)

          if [[ -z "$lang_links" ]]; then
            echo "No language links found"
            echo "dictionaries=[]" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Filter for *-eng dictionaries (any language to English)
          eng_dicts=()
          while IFS= read -r link; do
            if [[ "$link" == *"-eng" && "$link" != "eng-eng" ]]; then
              eng_dicts+=("$link")
              echo "Found: $link"
            fi
          done <<< "$lang_links"

          # Remove duplicates and sort
          if [[ ${#eng_dicts[@]} -gt 0 ]]; then
            readarray -t unique_dicts < <(printf "%s\n" "${eng_dicts[@]}" | sort -u)
          else
            unique_dicts=()
          fi

          if [[ ${#unique_dicts[@]} -eq 0 ]]; then
            echo "No *-eng dictionaries found"
            echo "dictionaries=[]" >> $GITHUB_OUTPUT
          else
            echo "Found ${#unique_dicts[@]} *-eng dictionaries"
            # Convert array to JSON
            json_array="["
            for ((i=0; i<${#unique_dicts[@]}; i++)); do
              if [[ $i -gt 0 ]]; then
                json_array+=","
              fi
              json_array+="\"${unique_dicts[$i]}\""
            done
            json_array+="]"
            echo "dictionaries=$json_array" >> $GITHUB_OUTPUT
          fi

      - name: Set output
        id: set-output
        run: |
          if [[ -n "${{ steps.discover.outputs.dictionaries }}" ]]; then
            echo "dictionaries=${{ steps.discover.outputs.dictionaries }}" >> $GITHUB_OUTPUT
          else
            echo "dictionaries=[]" >> $GITHUB_OUTPUT
          fi

  process-all-dictionaries:
    needs: discover-dictionaries
    runs-on: ubuntu-latest
    outputs:
      has_files: ${{ steps.check-output.outputs.has_files }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y p7zip-full zip curl

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install pyglossary and dependencies
        run: pip install pyglossary lxml beautifulsoup4 python-idzip tqdm pyicu

      - name: Parse dictionary list
        id: parse-dicts
        run: |
          echo "Debug: Raw dictionaries JSON: '${{ needs.discover-dictionaries.outputs.dictionaries }}'"

          # Read the JSON array and convert to bash array
          dicts_json='${{ needs.discover-dictionaries.outputs.dictionaries }}'

          if [[ "$dicts_json" == "[]" ]] || [[ -z "$dicts_json" ]]; then
            echo "No dictionaries to process (empty or null)"
            echo "dictionaries_list=" >> $GITHUB_OUTPUT
            echo "has_files=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Debug: Show the JSON
          echo "Parsing dictionaries JSON: $dicts_json"

          # Remove brackets and quotes, then convert to array
          dicts_json_clean=$(echo "$dicts_json" | sed 's/\[\|\]//g' | sed 's/"//g')
          echo "Cleaned JSON: $dicts_json_clean"

          IFS=',' read -r -a DICT_ARRAY <<< "$dicts_json_clean"

          echo "Processing ${#DICT_ARRAY[@]} dictionaries sequentially"
          echo "Dictionary list: ${DICT_ARRAY[@]}"

          # Store array as string for use in subsequent steps
          printf -v dicts_str '%s,' "${DICT_ARRAY[@]}"
          dicts_str=${dicts_str%,}
          echo "dictionaries_list=$dicts_str" >> $GITHUB_OUTPUT
          echo "has_files=true" >> $GITHUB_OUTPUT

      - name: Process dictionaries sequentially
        env:
          DICTIONARIES: ${{ steps.parse-dicts.outputs.dictionaries_list }}
        run: |
          # Split the comma-separated list into array
          IFS=',' read -r -a DICT_ARRAY <<< "$DICTIONARIES"

          [[ ${#DICT_ARRAY[@]} -eq 0 ]] && echo "No dictionaries to process" && exit 0

          mkdir -p _convert

          # Track if any dictionary was actually processed
          processed_count=0

          for lang_pair in "${DICT_ARRAY[@]}"; do
            temp_dir="temp_${lang_pair}"
            mkdir -p "$temp_dir"
            cd "$temp_dir"

            clear_temp() {
              cd ..
              rm -rf "$temp_dir"
            }

            echo "Checking for latest version of $lang_pair..."
            base_url="https://download.freedict.org/dictionaries/$lang_pair/"
            echo "Checking URL: $base_url"

            # Try to fetch the dictionary page HTML
            html=$(curl -s -L -A "GitHub-Actions-CI" "$base_url")

            # Check if the page exists
            if [[ -z "$html" ]] || [[ "$html" == *"404 Not Found"* ]] || [[ "$html" == *"Not Found"* ]]; then
              echo "Dictionary $lang_pair not found or returned 404, skipping"
              clear_temp
              continue
            fi

            # Extract version numbers from the page
            versions=$(echo "$html" | grep -oP 'href="(\d{4}\.\d{2}\.\d{2}/)"' | grep -oP '\d{4}\.\d{2}\.\d{2}' | sort -V)
            versions=${versions:-$(echo "$html" | grep -oP 'href="(\d+\.\d+\.\d+/)"' | grep -oP '\d+\.\d+\.\d+' | sort -V)}
            versions=${versions:-$(echo "$html" | grep -oP "freedict-$lang_pair-\d+\.\d+\.\d+" | grep -oP "\d+\.\d+\.\d+" | sort -V)}

            [[ -z "$versions" ]] && echo "No versions found for $lang_pair, skipping" && clear_temp && continue

            # Get the latest (highest) version
            latest_version=$(echo "$versions" | tail -1)
            echo "Latest version for $lang_pair: $latest_version"

            # Create filesystem-safe version identifier
            [[ "$latest_version" =~ ^[0-9]{4}\.[0-9]{2}\.[0-9]{2}$ ]] && \
              file_version=$(echo "$latest_version" | sed 's/\.//g') || \
              file_version="$latest_version"
            tag_version="$latest_version"

            # Try to download the source file
            filename="freedict-${lang_pair}-${latest_version}.src.tar.xz"
            downloaded=false

            # Try multiple possible URL patterns
            for url in \
              "${base_url}${latest_version}/$filename" \
              "${base_url}$filename" \
              "https://download.freedict.org/dictionaries/$lang_pair/$latest_version/$filename" \
              "https://download.freedict.org/dictionaries/$lang_pair/$filename"
            do
              echo "Trying to download from: $url"
              curl -f -L -o "$filename" "$url" && downloaded=true && break
              sleep 1
            done

            [[ "$downloaded" != "true" ]] && echo "Failed to download $lang_pair $latest_version, skipping" && clear_temp && continue

            # Extract the downloaded archive
            echo "Extracting $filename"
            7z x "$filename" -o. 2>/dev/null || tar -xf "$filename" || \
              { echo "Failed to extract $filename"; clear_temp; continue; }

            # Extract the .tar file (if it exists)
            tar_file="${filename%.xz}"
            [[ -f "$tar_file" ]] && { 7z x "$tar_file" -o. 2>/dev/null || tar -xf "$tar_file"; } && rm -f "$tar_file"

            # Find and rename the extracted directory
            src_dir="freedict-${lang_pair}-${file_version}"

            # Try common directory name patterns
            for dir in \
              "$lang_pair" \
              "${lang_pair/_/-}" \
              "$(echo $lang_pair | cut -d'-' -f1)-$(echo $lang_pair | cut -d'-' -f2)" \
              "freedict-${lang_pair}-${latest_version}" \
              "freedict-${lang_pair}-${file_version}"
            do
              [[ -d "$dir" && "$dir" != "$src_dir" ]] && mv "$dir" "$src_dir" && break
            done

            # Fallback: if directory not found with expected names
            if [[ ! -d "$src_dir" ]]; then
              found_dir=$(find . -maxdepth 1 -type d -name "*${lang_pair/_/-}*" -o -name "*${lang_pair}*" | grep -v "^\.$" | head -1)
              [[ -n "$found_dir" ]] && mv "$found_dir" "$src_dir" || mkdir -p "$src_dir"
            fi

            # Find the TEI file
            src_lang=$(echo $lang_pair | cut -d'-' -f1)
            tgt_lang=$(echo $lang_pair | cut -d'-' -f2)
            tei_file=""

            for file in \
              "$src_dir/$src_lang-$tgt_lang.tei" \
              "$src_dir/$lang_pair.tei" \
              "$src_dir/${lang_pair/_/-}.tei" \
              "$src_dir/freedict-$lang_pair.tei" \
              "$src_dir/freedict-${lang_pair/_/-}.tei" \
              "$src_dir/tei" \
              "$src_dir/*.tei" \
              "$(find "$src_dir" -name "*.tei" -type f 2>/dev/null | head -1)"
            do
              [[ -f "$file" ]] && tei_file="$file" && break
            done

            # Fallback: look for XML files
            [[ -z "$tei_file" ]] && tei_file=$(find "$src_dir" -name "*.xml" -type f 2>/dev/null | head -1)
            [[ -z "$tei_file" ]] && echo "ERROR: No TEI or XML file found for $lang_pair" && clear_temp && continue

            echo "Found TEI file: $tei_file"
            base_filename="freedict-${lang_pair}-${file_version}"

            # tabfile
            pyglossary "$tei_file" "_${base_filename}.txt" --read-format=FreeDict --write-format=Tabfile

            # tabfile-formatted
            python ../text_format.py "_${base_filename}.txt" "_${base_filename}-formatted.txt"

            # stardict
            pyglossary "_${base_filename}-formatted.txt" "${base_filename}-stardict" --read-format=Tabfile --write-format=Stardict --name="FreeDict-$lang_pair"

            # tabfile-formatted-html2ansi
            python ../html2ansi.py "_${base_filename}-formatted.txt" "_${base_filename}-formatted-html2ansi.txt"

            # sdcv
            pyglossary "_${base_filename}-formatted-html2ansi.txt" "${base_filename}-sdcv" --read-format=Tabfile --write-format=Stardict --name="FreeDict-$lang_pair"

            # dictd
            pyglossary "_${base_filename}-formatted-html2ansi.txt" "${base_filename}-dictd" --read-format=Tabfile --write-format=DictOrg --write-options="dictzip=true" --name="FreeDict-$lang_pair"

            # yomichan
            pyglossary "_${base_filename}-formatted.txt" "${base_filename}-yomichan.zip" --read-format=Tabfile --write-format=Yomichan --name="FreeDict-$lang_pair"

            # aard2
            pyglossary "_${base_filename}-formatted.txt" "${base_filename}-aard2.slob" --read-format=Tabfile --write-format=Aard2Slob --name="FreeDict-$lang_pair"

            # ZIP stardict
            for base in *-stardict.ifo; do
                prefix="${base%.ifo}"
                zip -j "${prefix}.zip" "$prefix.ifo" "$prefix.dict" "$prefix.idx" 2>/dev/null && rm "$prefix.ifo" "$prefix.dict" "$prefix.idx"
            done

            # ZIP sdcv
            for base in *-sdcv.ifo; do
                prefix="${base%.ifo}"
                zip -j "${prefix}.zip" "$prefix.ifo" "$prefix.dict" "$prefix.idx" "$prefix.syn" 2>/dev/null && rm "$prefix.ifo" "$prefix.dict" "$prefix.idx" "$prefix.syn"
            done

            # ZIP dictd
            zip -j "${base_filename}-dictd.zip" "${base_filename}-dictd.dict.dz" "${base_filename}-dictd.index" && rm "${base_filename}-dictd.dict.dz" "${base_filename}-dictd.index"

            for file in "${base_filename}"* "_${base_filename}"*; do
              if [[ -f "$file" ]]; then
                mv "$file" "../_convert/" && echo "Moved: $file"
              fi
            done

            processed_count=$((processed_count + 1))
            clear_temp
            sleep 2
          done

          echo "Total dictionaries processed: $processed_count"
          if [[ $processed_count -eq 0 ]]; then
            echo "No new dictionaries were processed"
          else
            echo "Successfully processed $processed_count dictionaries"
          fi

      - name: Check if files were generated
        id: check-output
        run: |
          if [ -n "$(ls -A _convert 2>/dev/null || true)" ]; then
            echo "Files found in _convert"
            ls -la _convert/
            echo "has_files=true" >> $GITHUB_OUTPUT
          else
            echo "No files found in _convert"
            echo "has_files=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload processed files
        if: steps.check-output.outputs.has_files == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: _convert
          path: _convert/
          retention-days: 1
          if-no-files-found: warn

  create-combined-release:
    needs: [discover-dictionaries, process-all-dictionaries]
    runs-on: ubuntu-latest
    if: ${{ !failure() && !cancelled() && needs.process-all-dictionaries.outputs.has_files == 'true' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y zip

      - name: Get current date for release tag
        id: date
        run: |
          # Get current date in YYYYMMDD format
          current_date=$(date -u +"%Y%m%d")
          echo "RELEASE_DATE=$current_date" >> $GITHUB_OUTPUT
          echo "Release will be tagged as: $current_date"

      - name: Download processed dictionaries
        uses: actions/download-artifact@v4
        with:
          name: _convert
          path: _convert

      - name: Create collection ZIP files
        run: |
          mkdir -p _collect
          cp _convert/* _collect/ 2>/dev/null || true
          cd _collect
          zip -j all-stardict.zip *-stardict.zip
          zip -j all-sdcv.zip *-sdcv.zip
          zip -j all-dictd.zip *-dictd.zip
          zip -j all-yomichan.zip *-yomichan.zip
          zip -j all-aard2.zip *.slob
          zip -j _all-formatted-txt.zip _*-formatted.txt
          zip -j _all-formatted-html2ansi-txt.zip _*-formatted-html2ansi.txt

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.date.outputs.RELEASE_DATE }}
          name: FreeDict *-eng released ${{ steps.date.outputs.RELEASE_DATE }}
          files: |
            _convert/*.zip
            _convert/*.slob
            _collect/*.zip
          overwrite_files: true
